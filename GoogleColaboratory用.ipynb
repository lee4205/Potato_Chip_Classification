{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Potato.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhp30IWwKiMU8LCdg5FxlL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee4205/Potato_Chip_Classification/blob/master/GoogleColaboratory%E7%94%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7ti49hrDjPr"
      },
      "source": [
        "!git clone https://user:password@github.com/lee4205/Potato_Chip_Classification.git\r\n",
        "!git config --global user.email \"email@gmail.com\"\r\n",
        "!git config --global user.name \"username\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFARnN0VRZA6"
      },
      "source": [
        "cd Potato_Chip_Classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b05ByfvyRqZ6"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\r\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import subprocess\r\n",
        "import random\r\n",
        "import os\r\n",
        "# デバッグ用\r\n",
        "pd.set_option(\"display.max_rows\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oviWvP8IR9TN"
      },
      "source": [
        "IMAGE_WIDTH = 120\r\n",
        "IMAGE_HEIGHT = 160\r\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "IMAGE_CHANNELS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT3AtWEtJthK"
      },
      "source": [
        "cwd = os.getcwd()\r\n",
        "subprocess.run([\"mkdir \" + cwd + \"/dataset\"], shell=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn-I-zeMgTKJ"
      },
      "source": [
        "filename = []\r\n",
        "taste = []\r\n",
        "flavors = os.listdir(cwd + \"/potato-chips\")\r\n",
        "for flavor in flavors:\r\n",
        "    images = os.listdir(cwd + f\"/potato-chips/{flavor}\")\r\n",
        "    for image in images:\r\n",
        "      taste.append(flavor)\r\n",
        "      filename.append(image)\r\n",
        "    subprocess.run([\"cp \" + cwd + \"/potato-chips/\" + flavor + \"/*.jpg \" + cwd + \"/dataset\"], shell=True)\r\n",
        "df = pd.DataFrame({\"filename\" : filename, \"taste\" : taste})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3r7Ck4pOV-G"
      },
      "source": [
        "# デバッグ用\r\n",
        "print(df)\r\n",
        "print(df.shape)\r\n",
        "df[\"taste\"].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARN5UKshSY64"
      },
      "source": [
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(units=512, activation=\"relu\"))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(2, activation=\"softmax\"))\r\n",
        "\r\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"rmsprop\", metrics = [\"accuracy\"])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AsZDBUmoA9O"
      },
      "source": [
        "earlystop = EarlyStopping(patience=10)\r\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_accuracy\", \t\r\n",
        "                                            patience=2, \t\r\n",
        "                                            verbose=1, \t\r\n",
        "                                            factor=0.3, \t\r\n",
        "                                            min_lr=0.0001)\t\r\n",
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msXhk2zZU2yF"
      },
      "source": [
        "train_df, validate_df = train_test_split(df, train_size=0.6, random_state=42)\r\n",
        "validate_df, test_df = train_test_split(validate_df, test_size=0.5, random_state=42)\r\n",
        "train_df = train_df.reset_index(drop=True)\r\n",
        "validate_df = validate_df.reset_index(drop=True)\r\n",
        "test_df = test_df.reset_index(drop=True)\r\n",
        "total_train = train_df.shape[0]\r\n",
        "total_validate = validate_df.shape[0]\r\n",
        "total_test = test_df.shape[0]\r\n",
        "batch_size = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f31jECUtU4xm"
      },
      "source": [
        "# デバッグ用\r\n",
        "train_df[\"taste\"].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUNiXfzLVBRs"
      },
      "source": [
        "# デバッグ用\r\n",
        "validate_df[\"taste\"].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5NLcUZsDT9L"
      },
      "source": [
        "# デバッグ用\r\n",
        "test_df[\"taste\"].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BRLZpeRJu__"
      },
      "source": [
        "analyse = input(\"以下の味を1つ選択して入力する\\n\\\r\n",
        "consomme-punch, kyusyu-shoyu, norishio, norishio-punch, \\\r\n",
        "shiawase-butter, shoyu-mayo, usushio\\n\\\r\n",
        "選択した味:\")\r\n",
        "new_taste = dict.fromkeys(flavors, 0)\r\n",
        "new_taste.update({analyse: 1})\r\n",
        "train_df[\"taste\"] = train_df[\"taste\"].replace(new_taste)\r\n",
        "validate_df[\"taste\"] = validate_df[\"taste\"].replace(new_taste)\r\n",
        "test_df[\"taste\"] = test_df[\"taste\"].replace(new_taste)\r\n",
        "train_df[\"taste\"] = train_df[\"taste\"].replace({0: \"others\", 1: analyse})\r\n",
        "validate_df[\"taste\"] = validate_df[\"taste\"].replace({0: \"others\", 1: analyse})\r\n",
        "test_df[\"taste\"] = test_df[\"taste\"].replace({0: \"others\", 1: analyse})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyzO8d8AUf68"
      },
      "source": [
        "# デバッグ用\r\n",
        "train_df[\"taste\"].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5HLE9fdUhHn"
      },
      "source": [
        "# デバッグ用\r\n",
        "validate_df[\"taste\"].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZleEdbkUiIc"
      },
      "source": [
        "# デバッグ用\r\n",
        "test_df[\"taste\"].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkIE5HF3VIbt"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\r\n",
        "    rotation_range=15,\r\n",
        "    rescale=1./255,\r\n",
        "    shear_range=0.1,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True,\r\n",
        "    fill_mode=\"nearest\",\r\n",
        "    width_shift_range=0.1,\r\n",
        "    height_shift_range=0.1)\r\n",
        "train_generator = train_datagen.flow_from_dataframe(\r\n",
        "    train_df, \r\n",
        "    cwd+\"/dataset/\", \r\n",
        "    x_col=\"filename\",\r\n",
        "    y_col=\"taste\",\r\n",
        "    target_size=IMAGE_SIZE,\r\n",
        "    class_mode=\"categorical\",\r\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01o-LMPYV_nX"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\r\n",
        "    validate_df, \r\n",
        "    cwd + \"/dataset/\", \r\n",
        "    x_col=\"filename\",\r\n",
        "    y_col=\"taste\",\r\n",
        "    target_size=IMAGE_SIZE,\r\n",
        "    class_mode=\"categorical\",\r\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjpzT_T2WJyH"
      },
      "source": [
        "# サンプル\r\n",
        "sample = random.choice(filename)\r\n",
        "sample_image = load_img(cwd + \"/dataset/\" + sample)\r\n",
        "print(sample)\r\n",
        "plt.imshow(sample_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8f9hGdD4SNZ"
      },
      "source": [
        "# サンプル\r\n",
        "sample_df = train_df.sample(n=1).reset_index(drop=True)\r\n",
        "sample_generator = train_datagen.flow_from_dataframe(\r\n",
        "    sample_df, \r\n",
        "    cwd + \"/dataset/\", \r\n",
        "    x_col=\"filename\",\r\n",
        "    y_col=\"taste\",\r\n",
        "    target_size=IMAGE_SIZE,\r\n",
        "    class_mode=\"categorical\")\r\n",
        "plt.figure(figsize=(12, 12))\r\n",
        "for i in range(0, 9):\r\n",
        "    plt.subplot(3, 3, i+1)\r\n",
        "    for X_batch, Y_batch in sample_generator:\r\n",
        "        image = X_batch[0]\r\n",
        "        plt.imshow(image)\r\n",
        "        break\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lxh9-2LWTfN"
      },
      "source": [
        "epochs = 50\r\n",
        "history = model.fit_generator(\r\n",
        "    train_generator, \r\n",
        "    epochs=epochs,\r\n",
        "    validation_data=validation_generator,\r\n",
        "    validation_steps=total_validate//batch_size,\r\n",
        "    steps_per_epoch=total_train//batch_size,\r\n",
        "    callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gaj92lIM6iR"
      },
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNs9a0vjM8eY"
      },
      "source": [
        "fig, axs = plt.subplots(1,2,figsize=(15,5))\r\n",
        "axs[0].plot(range(1,len(history.history[\"accuracy\"])+1),history.history[\"accuracy\"])\r\n",
        "axs[0].plot(range(1,len(history.history[\"val_accuracy\"])+1),history.history[\"val_accuracy\"])\r\n",
        "axs[0].set_title(\"Model Accuracy\")\r\n",
        "axs[0].set_ylabel(\"Accuracy\")\r\n",
        "axs[0].set_xlabel(\"Epoch\")\r\n",
        "axs[0].set_xticks(np.arange(1,len(history.history[\"accuracy\"])+1),len(history.history[\"accuracy\"])/10)\r\n",
        "axs[0].legend([\"train\", \"val\"], loc=\"best\")\r\n",
        "axs[1].plot(range(1,len(history.history[\"loss\"])+1),history.history[\"loss\"])\r\n",
        "axs[1].plot(range(1,len(history.history[\"val_loss\"])+1),history.history[\"val_loss\"])\r\n",
        "axs[1].set_title(\"Model Loss\")\r\n",
        "axs[1].set_ylabel(\"Loss\")\r\n",
        "axs[1].set_xlabel(\"Epoch\")\r\n",
        "axs[1].set_xticks(np.arange(1,len(history.history[\"loss\"])+1),len(history.history[\"loss\"])/10)\r\n",
        "axs[1].legend([\"train\", \"val\"], loc=\"best\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqjTGW1w4-KW"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "test_generator = test_datagen.flow_from_dataframe(\r\n",
        "    test_df,\r\n",
        "    cwd+\"/dataset/\",\r\n",
        "    x_col=\"filename\",\r\n",
        "    y_col=None,\r\n",
        "    class_mode=None,\r\n",
        "    target_size=IMAGE_SIZE,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2UALfPI5Gwk"
      },
      "source": [
        "predict = model.predict(test_generator, steps=np.ceil(total_test/batch_size))\r\n",
        "test_df[\"taste\"] = np.argmax(predict, axis=-1)\r\n",
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\r\n",
        "test_df[\"taste\"] = test_df[\"taste\"].replace(label_map)\r\n",
        "test_df[\"taste\"].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_obeDhj5dYq"
      },
      "source": [
        "sample_test = test_df.head(25)\r\n",
        "sample_test.head()\r\n",
        "plt.figure(figsize=(24, 24))\r\n",
        "for index, row in sample_test.iterrows():\r\n",
        "    filename = row[\"filename\"]\r\n",
        "    category = row[\"taste\"]\r\n",
        "    img = load_img(cwd + \"/dataset/\" + filename, target_size=IMAGE_SIZE)\r\n",
        "    plt.subplot(5, 5, index + 1)\r\n",
        "    plt.imshow(img)\r\n",
        "    plt.xlabel(\"{}\".format(category) + \"(\" + filename + \")\" )\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}