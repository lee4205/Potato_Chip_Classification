{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3++erODhdnXvDWFAp0OOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee4205/Potato_Chip_Classification/blob/master/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k35AtEiCVshd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2339bb-54c4-40e0-ebab-35813dfd0a86"
      },
      "source": [
        "!git clone https://@github.com/lee4205/Potato_Chip_Classification.git\r\n",
        "!git config --global user.email \"leejinyien4205@gmail.com\"\r\n",
        "!git config --global user.name \"lee4205\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Potato_Chip_Classification'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
            "remote: Compressing objects: 100% (180/180), done.\u001b[K\n",
            "remote: Total 2031 (delta 85), reused 81 (delta 23), pack-reused 1823\u001b[K\n",
            "Receiving objects: 100% (2031/2031), 156.60 MiB | 34.15 MiB/s, done.\n",
            "Resolving deltas: 100% (187/187), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzSsfXhDXeC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec86163-bf71-477d-f724-638c93cb8b05"
      },
      "source": [
        "cd Potato_Chip_Classification"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Potato_Chip_Classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0wE7mc3t8yl"
      },
      "source": [
        "import os\r\n",
        "import csv\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYkLaoLLDBLP"
      },
      "source": [
        "image_width = 1280 // 10\r\n",
        "image_height = 960 // 10\r\n",
        "image_size = (image_width, image_height)\r\n",
        "image_channel = 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doAcAXrV8ZwG"
      },
      "source": [
        "cwd = os.getcwd()\r\n",
        "flavors = os.listdir(cwd + \"/potato-chips\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WngFwtNW8gna"
      },
      "source": [
        "pixels = []\r\n",
        "pixel = 0\r\n",
        "for x in range(image_width * image_height):\r\n",
        "    pixel += 1\r\n",
        "    pixels.append('pixel' + str(pixel))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc0eXM7Lt7FR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44702467-8c60-46bf-b54f-b7b491d13779"
      },
      "source": [
        "with open(\"potato_chips.csv\", 'a') as c:\r\n",
        "    csv_input = csv.writer(c)\r\n",
        "    header = [\"image\", \"flavor\"]\r\n",
        "    header.extend(pixels)\r\n",
        "    csv_input.writerow(header)\r\n",
        "\r\n",
        "    for flavor in flavors:\r\n",
        "        print(\"loading image from \" + flavor + \" ...\")\r\n",
        "        images = os.listdir(cwd + f\"/potato-chips/{flavor}\")\r\n",
        "        for image in images:\r\n",
        "            rgb_image = Image.open(cwd + f\"/potato-chips/{flavor}/\" + image)\r\n",
        "            grey_image = rgb_image.convert('L').resize((image_width, image_height))\r\n",
        "            pixel_data = np.asarray(grey_image.getdata(), dtype=np.int).reshape((grey_image.size[1], grey_image.size[0]))\r\n",
        "            pixel_data = pixel_data.flatten()\r\n",
        "            image_data = [image, flavors.index(flavor)]\r\n",
        "            image_data.extend(pixel_data)\r\n",
        "            csv_input.writerow(image_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading image from consomme-punch ...\n",
            "loading image from norishio-punch ...\n",
            "loading image from norishio ...\n",
            "loading image from shiawase-butter ...\n",
            "loading image from kyusyu-shoyu ...\n",
            "loading image from usushio ...\n",
            "loading image from shoyu-mayo ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS9Bq7TW8mVq"
      },
      "source": [
        "df = pd.read_csv(cwd + \"/potato_chips.csv\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVYM6tSiHmfg"
      },
      "source": [
        "train_df, validate_df = train_test_split(df, train_size=0.6, random_state=42)\r\n",
        "validate_df, test_df = train_test_split(validate_df, test_size=0.5, random_state=42)\r\n",
        "train_df = train_df.reset_index(drop=True)\r\n",
        "validate_df = validate_df.reset_index(drop=True)\r\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_hPySlv9gRp"
      },
      "source": [
        "# デバッグ用\r\n",
        "# train_df\r\n",
        "# validate_df\r\n",
        "# test_df\r\n",
        "# plt.figure(figsize=(15, 15))\r\n",
        "# sns.set_style(\"darkgrid\")\r\n",
        "# sns.countplot(train_df['flavor'])\r\n",
        "# sns.countplot(validate_df['flavor'])\r\n",
        "# sns.countplot(test_df['flavor'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygOQHOMdLPPg"
      },
      "source": [
        "y_train = train_df['flavor']\r\n",
        "y_validate = validate_df['flavor']\r\n",
        "y_test = test_df['flavor']\r\n",
        "y = test_df['flavor']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYQtpkRi8-g9"
      },
      "source": [
        "del train_df['image'], train_df['flavor']\r\n",
        "del validate_df['image'], validate_df['flavor']\r\n",
        "del test_df['image'], test_df['flavor']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1299Dfp8MEls"
      },
      "source": [
        "label_binarizer = LabelBinarizer()\r\n",
        "y_train = label_binarizer.fit_transform(y_train)\r\n",
        "y_validate = label_binarizer.fit_transform(y_validate)\r\n",
        "y_test = label_binarizer.fit_transform(y_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PmNQX_dMLB_"
      },
      "source": [
        "x_train = train_df.values\r\n",
        "x_validate = validate_df.values\r\n",
        "x_test = test_df.values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP0po7rsMSrP"
      },
      "source": [
        "x_train = x_train / 255\r\n",
        "x_validate = x_validate / 255\r\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djNdQBjiMXrg"
      },
      "source": [
        "x_train = x_train.reshape(-1, image_height, image_width, 1)\r\n",
        "x_validate = x_validate.reshape(-1, image_height, image_width, 1)\r\n",
        "x_test = x_test.reshape(-1, image_height, image_width, 1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2LL0h6n9cW4"
      },
      "source": [
        "# デバッグ用\r\n",
        "# f, ax = plt.subplots(3, 3)\r\n",
        "# f.set_size_inches(10, 10)\r\n",
        "# k = 0\r\n",
        "# for i in range(3):\r\n",
        "#     for j in range(3):\r\n",
        "#         ax[i, j].imshow(x_train[k].reshape(image_height, image_width), cmap=\"gray\")\r\n",
        "#         k += 1\r\n",
        "#     plt.tight_layout() "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ5pLk6RnGD3"
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=False,\r\n",
        "                             samplewise_center=False,\r\n",
        "                             featurewise_std_normalization=False,\r\n",
        "                             samplewise_std_normalization=False,\r\n",
        "                             zca_whitening=False,\r\n",
        "                             rotation_range=10,\r\n",
        "                             zoom_range=0.1,\r\n",
        "                             width_shift_range=0.1,\r\n",
        "                             height_shift_range=0.1,\r\n",
        "                             horizontal_flip=False,\r\n",
        "                             vertical_flip=False)\r\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JRiqkWCnfJf"
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\r\n",
        "                                            patience=2,\r\n",
        "                                            verbose=1,\r\n",
        "                                            factor=0.5,\r\n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-M2qMLmnkHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362131ae-c5e9-4c46-f0ec-d7da2fa0830d"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv2D(75, (3, 3), strides=1, padding='same', activation='relu', input_shape=(image_width, image_height, image_channel)))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\r\n",
        "model.add(Conv2D(50, (3, 3), strides=1, padding='same', activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\r\n",
        "model.add(Conv2D(25, (3, 3), strides=1, padding='same', activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(units=512, activation='relu'))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(Dense(units=7, activation='softmax'))\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 128, 96, 75)       750       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 96, 75)       300       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 64, 48, 75)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 64, 48, 50)        33800     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64, 48, 50)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 48, 50)        200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 24, 50)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 24, 25)        11275     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 24, 25)        100       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 12, 25)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4800)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               2458112   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 2,508,128\n",
            "Trainable params: 2,507,828\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhF9GuqlnpVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17989fef-9770-4736-a232-7c552e6c52e6"
      },
      "source": [
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=5),\r\n",
        "                    epochs=500,\r\n",
        "                    validation_data=(x_validate, y_validate),\r\n",
        "                    callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "86/86 [==============================] - ETA: 0s - loss: 4.5398 - accuracy: 0.2765WARNING:tensorflow:Model was constructed with shape (None, 128, 96, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 96, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 96, 128, 1).\n",
            "86/86 [==============================] - 28s 311ms/step - loss: 4.5300 - accuracy: 0.2769 - val_loss: 4.9042 - val_accuracy: 0.1958\n",
            "Epoch 2/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 2.4117 - accuracy: 0.4018 - val_loss: 8.2780 - val_accuracy: 0.1958\n",
            "Epoch 3/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 1.5488 - accuracy: 0.5288 - val_loss: 6.8122 - val_accuracy: 0.1958\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 4/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 1.1325 - accuracy: 0.6091 - val_loss: 5.7422 - val_accuracy: 0.1958\n",
            "Epoch 5/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.9371 - accuracy: 0.6540 - val_loss: 3.6461 - val_accuracy: 0.3007\n",
            "Epoch 6/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.9297 - accuracy: 0.6694 - val_loss: 1.9623 - val_accuracy: 0.4476\n",
            "Epoch 7/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.8852 - accuracy: 0.7342 - val_loss: 1.0240 - val_accuracy: 0.6993\n",
            "Epoch 8/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.6986 - accuracy: 0.7562 - val_loss: 1.0542 - val_accuracy: 0.6643\n",
            "Epoch 9/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.7631 - accuracy: 0.7269 - val_loss: 0.5625 - val_accuracy: 0.7762\n",
            "Epoch 10/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.7045 - accuracy: 0.7372 - val_loss: 1.2103 - val_accuracy: 0.6084\n",
            "Epoch 11/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.5081 - accuracy: 0.8280 - val_loss: 2.1780 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 12/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.6374 - accuracy: 0.7685 - val_loss: 0.3875 - val_accuracy: 0.8601\n",
            "Epoch 13/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.4314 - accuracy: 0.8538 - val_loss: 0.4213 - val_accuracy: 0.8252\n",
            "Epoch 14/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.4302 - accuracy: 0.8648 - val_loss: 0.3968 - val_accuracy: 0.8531\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 15/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.3737 - accuracy: 0.8711 - val_loss: 0.3910 - val_accuracy: 0.8601\n",
            "Epoch 16/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.3940 - accuracy: 0.8630 - val_loss: 0.3948 - val_accuracy: 0.8601\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 17/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.3275 - accuracy: 0.9201 - val_loss: 0.3659 - val_accuracy: 0.8671\n",
            "Epoch 18/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.2738 - accuracy: 0.9113 - val_loss: 0.3706 - val_accuracy: 0.8741\n",
            "Epoch 19/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.2203 - accuracy: 0.9238 - val_loss: 0.3966 - val_accuracy: 0.8811\n",
            "Epoch 20/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.2679 - accuracy: 0.9117 - val_loss: 0.3901 - val_accuracy: 0.8741\n",
            "Epoch 21/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.2551 - accuracy: 0.9232 - val_loss: 0.2688 - val_accuracy: 0.9091\n",
            "Epoch 22/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.2156 - accuracy: 0.9419 - val_loss: 0.2821 - val_accuracy: 0.9091\n",
            "Epoch 23/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.3356 - accuracy: 0.8904 - val_loss: 0.3004 - val_accuracy: 0.8951\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 24/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.2022 - accuracy: 0.9239 - val_loss: 0.3226 - val_accuracy: 0.8741\n",
            "Epoch 25/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.2961 - accuracy: 0.8864 - val_loss: 0.3086 - val_accuracy: 0.9091\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 26/500\n",
            "86/86 [==============================] - 27s 308ms/step - loss: 0.1989 - accuracy: 0.9333 - val_loss: 0.3288 - val_accuracy: 0.8881\n",
            "Epoch 27/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.2761 - accuracy: 0.9184 - val_loss: 0.3067 - val_accuracy: 0.9021\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 28/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.1770 - accuracy: 0.9473 - val_loss: 0.2990 - val_accuracy: 0.8951\n",
            "Epoch 29/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.2355 - accuracy: 0.9339 - val_loss: 0.3152 - val_accuracy: 0.8951\n",
            "Epoch 30/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.2402 - accuracy: 0.9205 - val_loss: 0.3051 - val_accuracy: 0.8951\n",
            "Epoch 31/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.3236 - accuracy: 0.8818 - val_loss: 0.3140 - val_accuracy: 0.8881\n",
            "Epoch 32/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.2023 - accuracy: 0.9400 - val_loss: 0.3114 - val_accuracy: 0.8951\n",
            "Epoch 33/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1858 - accuracy: 0.9337 - val_loss: 0.3111 - val_accuracy: 0.9021\n",
            "Epoch 34/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.2038 - accuracy: 0.9372 - val_loss: 0.3009 - val_accuracy: 0.9021\n",
            "Epoch 35/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.2259 - accuracy: 0.9154 - val_loss: 0.3196 - val_accuracy: 0.8951\n",
            "Epoch 36/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.1757 - accuracy: 0.9381 - val_loss: 0.3138 - val_accuracy: 0.8951\n",
            "Epoch 37/500\n",
            "86/86 [==============================] - 26s 305ms/step - loss: 0.2012 - accuracy: 0.9320 - val_loss: 0.3120 - val_accuracy: 0.8951\n",
            "Epoch 38/500\n",
            "86/86 [==============================] - 26s 304ms/step - loss: 0.1988 - accuracy: 0.9509 - val_loss: 0.3137 - val_accuracy: 0.8951\n",
            "Epoch 39/500\n",
            "86/86 [==============================] - 26s 305ms/step - loss: 0.2061 - accuracy: 0.9235 - val_loss: 0.2999 - val_accuracy: 0.8951\n",
            "Epoch 40/500\n",
            "86/86 [==============================] - 26s 305ms/step - loss: 0.2074 - accuracy: 0.9267 - val_loss: 0.2985 - val_accuracy: 0.8951\n",
            "Epoch 41/500\n",
            "86/86 [==============================] - 26s 305ms/step - loss: 0.1885 - accuracy: 0.9484 - val_loss: 0.3037 - val_accuracy: 0.8951\n",
            "Epoch 42/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.2117 - accuracy: 0.9502 - val_loss: 0.3171 - val_accuracy: 0.8951\n",
            "Epoch 43/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.1493 - accuracy: 0.9646 - val_loss: 0.3002 - val_accuracy: 0.8951\n",
            "Epoch 44/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.1881 - accuracy: 0.9465 - val_loss: 0.2930 - val_accuracy: 0.9021\n",
            "Epoch 45/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.2341 - accuracy: 0.9242 - val_loss: 0.2827 - val_accuracy: 0.9021\n",
            "Epoch 46/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.2326 - accuracy: 0.9385 - val_loss: 0.2999 - val_accuracy: 0.8951\n",
            "Epoch 47/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.2441 - accuracy: 0.9100 - val_loss: 0.3039 - val_accuracy: 0.8881\n",
            "Epoch 48/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.2417 - accuracy: 0.9388 - val_loss: 0.2855 - val_accuracy: 0.9021\n",
            "Epoch 49/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.1980 - accuracy: 0.9068 - val_loss: 0.2930 - val_accuracy: 0.9021\n",
            "Epoch 50/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.2307 - accuracy: 0.9526 - val_loss: 0.2970 - val_accuracy: 0.8951\n",
            "Epoch 51/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1774 - accuracy: 0.9360 - val_loss: 0.2884 - val_accuracy: 0.8951\n",
            "Epoch 52/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.1897 - accuracy: 0.9408 - val_loss: 0.3043 - val_accuracy: 0.8811\n",
            "Epoch 53/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1940 - accuracy: 0.9509 - val_loss: 0.2885 - val_accuracy: 0.8951\n",
            "Epoch 54/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.2093 - accuracy: 0.9269 - val_loss: 0.2796 - val_accuracy: 0.8951\n",
            "Epoch 55/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.2168 - accuracy: 0.9134 - val_loss: 0.3058 - val_accuracy: 0.8881\n",
            "Epoch 56/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.2302 - accuracy: 0.9195 - val_loss: 0.3330 - val_accuracy: 0.8601\n",
            "Epoch 57/500\n",
            "86/86 [==============================] - 27s 308ms/step - loss: 0.2071 - accuracy: 0.9389 - val_loss: 0.3077 - val_accuracy: 0.8741\n",
            "Epoch 58/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1346 - accuracy: 0.9543 - val_loss: 0.3197 - val_accuracy: 0.8811\n",
            "Epoch 59/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.2304 - accuracy: 0.9066 - val_loss: 0.3104 - val_accuracy: 0.8881\n",
            "Epoch 60/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.1940 - accuracy: 0.9495 - val_loss: 0.3093 - val_accuracy: 0.8881\n",
            "Epoch 61/500\n",
            "86/86 [==============================] - 26s 304ms/step - loss: 0.1318 - accuracy: 0.9629 - val_loss: 0.3062 - val_accuracy: 0.8881\n",
            "Epoch 62/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1817 - accuracy: 0.9305 - val_loss: 0.3020 - val_accuracy: 0.8881\n",
            "Epoch 63/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1943 - accuracy: 0.9326 - val_loss: 0.3092 - val_accuracy: 0.8811\n",
            "Epoch 64/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.1943 - accuracy: 0.9486 - val_loss: 0.3120 - val_accuracy: 0.8811\n",
            "Epoch 65/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.2078 - accuracy: 0.9381 - val_loss: 0.2984 - val_accuracy: 0.8881\n",
            "Epoch 66/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1909 - accuracy: 0.9482 - val_loss: 0.2794 - val_accuracy: 0.8881\n",
            "Epoch 67/500\n",
            "86/86 [==============================] - 27s 308ms/step - loss: 0.1782 - accuracy: 0.9286 - val_loss: 0.2739 - val_accuracy: 0.8951\n",
            "Epoch 68/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.1747 - accuracy: 0.9491 - val_loss: 0.2807 - val_accuracy: 0.8951\n",
            "Epoch 69/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1423 - accuracy: 0.9613 - val_loss: 0.2773 - val_accuracy: 0.8951\n",
            "Epoch 70/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1716 - accuracy: 0.9393 - val_loss: 0.2757 - val_accuracy: 0.8951\n",
            "Epoch 71/500\n",
            "86/86 [==============================] - 26s 305ms/step - loss: 0.1510 - accuracy: 0.9712 - val_loss: 0.2604 - val_accuracy: 0.9091\n",
            "Epoch 72/500\n",
            "86/86 [==============================] - 26s 304ms/step - loss: 0.1602 - accuracy: 0.9596 - val_loss: 0.2715 - val_accuracy: 0.8951\n",
            "Epoch 73/500\n",
            "86/86 [==============================] - 26s 305ms/step - loss: 0.1719 - accuracy: 0.9579 - val_loss: 0.2852 - val_accuracy: 0.8811\n",
            "Epoch 74/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1695 - accuracy: 0.9322 - val_loss: 0.2794 - val_accuracy: 0.9021\n",
            "Epoch 75/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1617 - accuracy: 0.9506 - val_loss: 0.2684 - val_accuracy: 0.9021\n",
            "Epoch 76/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1470 - accuracy: 0.9637 - val_loss: 0.2705 - val_accuracy: 0.9021\n",
            "Epoch 77/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1543 - accuracy: 0.9588 - val_loss: 0.2611 - val_accuracy: 0.9091\n",
            "Epoch 78/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1289 - accuracy: 0.9771 - val_loss: 0.2668 - val_accuracy: 0.9091\n",
            "Epoch 79/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1386 - accuracy: 0.9535 - val_loss: 0.2835 - val_accuracy: 0.8951\n",
            "Epoch 80/500\n",
            "86/86 [==============================] - 28s 324ms/step - loss: 0.1919 - accuracy: 0.9258 - val_loss: 0.2876 - val_accuracy: 0.8951\n",
            "Epoch 81/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.1436 - accuracy: 0.9469 - val_loss: 0.2798 - val_accuracy: 0.8951\n",
            "Epoch 82/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.1667 - accuracy: 0.9414 - val_loss: 0.2922 - val_accuracy: 0.8811\n",
            "Epoch 83/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1843 - accuracy: 0.9558 - val_loss: 0.2758 - val_accuracy: 0.8951\n",
            "Epoch 84/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1610 - accuracy: 0.9537 - val_loss: 0.2714 - val_accuracy: 0.9021\n",
            "Epoch 85/500\n",
            "86/86 [==============================] - 26s 309ms/step - loss: 0.1304 - accuracy: 0.9697 - val_loss: 0.2886 - val_accuracy: 0.8951\n",
            "Epoch 86/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.1438 - accuracy: 0.9525 - val_loss: 0.2994 - val_accuracy: 0.8951\n",
            "Epoch 87/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.1730 - accuracy: 0.9353 - val_loss: 0.3026 - val_accuracy: 0.8881\n",
            "Epoch 88/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.2129 - accuracy: 0.9138 - val_loss: 0.2996 - val_accuracy: 0.8881\n",
            "Epoch 89/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.1617 - accuracy: 0.9566 - val_loss: 0.2680 - val_accuracy: 0.9161\n",
            "Epoch 90/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.1392 - accuracy: 0.9648 - val_loss: 0.2824 - val_accuracy: 0.9021\n",
            "Epoch 91/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.1272 - accuracy: 0.9653 - val_loss: 0.2829 - val_accuracy: 0.8951\n",
            "Epoch 92/500\n",
            "86/86 [==============================] - 28s 320ms/step - loss: 0.1443 - accuracy: 0.9720 - val_loss: 0.2841 - val_accuracy: 0.8881\n",
            "Epoch 93/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1774 - accuracy: 0.9491 - val_loss: 0.2733 - val_accuracy: 0.8951\n",
            "Epoch 94/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.1193 - accuracy: 0.9736 - val_loss: 0.2907 - val_accuracy: 0.8881\n",
            "Epoch 95/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1501 - accuracy: 0.9638 - val_loss: 0.2801 - val_accuracy: 0.8951\n",
            "Epoch 96/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1081 - accuracy: 0.9686 - val_loss: 0.2718 - val_accuracy: 0.9021\n",
            "Epoch 97/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1535 - accuracy: 0.9462 - val_loss: 0.2960 - val_accuracy: 0.8951\n",
            "Epoch 98/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0918 - accuracy: 0.9881 - val_loss: 0.2900 - val_accuracy: 0.8881\n",
            "Epoch 99/500\n",
            "86/86 [==============================] - 27s 308ms/step - loss: 0.1408 - accuracy: 0.9613 - val_loss: 0.2954 - val_accuracy: 0.8951\n",
            "Epoch 100/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1661 - accuracy: 0.9252 - val_loss: 0.2797 - val_accuracy: 0.9021\n",
            "Epoch 101/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1562 - accuracy: 0.9555 - val_loss: 0.2811 - val_accuracy: 0.8951\n",
            "Epoch 102/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1321 - accuracy: 0.9547 - val_loss: 0.2588 - val_accuracy: 0.9091\n",
            "Epoch 103/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.1304 - accuracy: 0.9672 - val_loss: 0.2700 - val_accuracy: 0.9091\n",
            "Epoch 104/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1194 - accuracy: 0.9594 - val_loss: 0.2803 - val_accuracy: 0.8951\n",
            "Epoch 105/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1917 - accuracy: 0.9363 - val_loss: 0.2810 - val_accuracy: 0.9021\n",
            "Epoch 106/500\n",
            "86/86 [==============================] - 27s 308ms/step - loss: 0.1167 - accuracy: 0.9676 - val_loss: 0.2886 - val_accuracy: 0.8951\n",
            "Epoch 107/500\n",
            "86/86 [==============================] - 26s 305ms/step - loss: 0.1039 - accuracy: 0.9758 - val_loss: 0.2850 - val_accuracy: 0.9091\n",
            "Epoch 108/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1567 - accuracy: 0.9399 - val_loss: 0.2893 - val_accuracy: 0.9091\n",
            "Epoch 109/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1043 - accuracy: 0.9719 - val_loss: 0.2717 - val_accuracy: 0.9091\n",
            "Epoch 110/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.1611 - accuracy: 0.9463 - val_loss: 0.2965 - val_accuracy: 0.8881\n",
            "Epoch 111/500\n",
            "86/86 [==============================] - 26s 305ms/step - loss: 0.1549 - accuracy: 0.9385 - val_loss: 0.3180 - val_accuracy: 0.8811\n",
            "Epoch 112/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.1308 - accuracy: 0.9701 - val_loss: 0.3159 - val_accuracy: 0.8881\n",
            "Epoch 113/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.1084 - accuracy: 0.9687 - val_loss: 0.3047 - val_accuracy: 0.8741\n",
            "Epoch 114/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1068 - accuracy: 0.9745 - val_loss: 0.3018 - val_accuracy: 0.8881\n",
            "Epoch 115/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.1485 - accuracy: 0.9595 - val_loss: 0.2864 - val_accuracy: 0.9021\n",
            "Epoch 116/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.1037 - accuracy: 0.9719 - val_loss: 0.2909 - val_accuracy: 0.8951\n",
            "Epoch 117/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.1744 - accuracy: 0.9377 - val_loss: 0.2857 - val_accuracy: 0.8951\n",
            "Epoch 118/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1587 - accuracy: 0.9578 - val_loss: 0.2880 - val_accuracy: 0.8881\n",
            "Epoch 119/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1089 - accuracy: 0.9738 - val_loss: 0.2777 - val_accuracy: 0.8881\n",
            "Epoch 120/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1268 - accuracy: 0.9602 - val_loss: 0.2745 - val_accuracy: 0.8881\n",
            "Epoch 121/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.1328 - accuracy: 0.9592 - val_loss: 0.2630 - val_accuracy: 0.8951\n",
            "Epoch 122/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1042 - accuracy: 0.9759 - val_loss: 0.2480 - val_accuracy: 0.9091\n",
            "Epoch 123/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0899 - accuracy: 0.9792 - val_loss: 0.2622 - val_accuracy: 0.9021\n",
            "Epoch 124/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1186 - accuracy: 0.9586 - val_loss: 0.2765 - val_accuracy: 0.9021\n",
            "Epoch 125/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1196 - accuracy: 0.9609 - val_loss: 0.2671 - val_accuracy: 0.9021\n",
            "Epoch 126/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.1186 - accuracy: 0.9631 - val_loss: 0.2914 - val_accuracy: 0.8951\n",
            "Epoch 127/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.1535 - accuracy: 0.9511 - val_loss: 0.2718 - val_accuracy: 0.8951\n",
            "Epoch 128/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.1382 - accuracy: 0.9541 - val_loss: 0.2760 - val_accuracy: 0.8951\n",
            "Epoch 129/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1118 - accuracy: 0.9640 - val_loss: 0.2753 - val_accuracy: 0.8741\n",
            "Epoch 130/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1361 - accuracy: 0.9545 - val_loss: 0.2596 - val_accuracy: 0.8951\n",
            "Epoch 131/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1033 - accuracy: 0.9667 - val_loss: 0.2440 - val_accuracy: 0.9161\n",
            "Epoch 132/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1523 - accuracy: 0.9502 - val_loss: 0.2656 - val_accuracy: 0.8951\n",
            "Epoch 133/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1570 - accuracy: 0.9484 - val_loss: 0.2791 - val_accuracy: 0.8881\n",
            "Epoch 134/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0994 - accuracy: 0.9758 - val_loss: 0.2809 - val_accuracy: 0.8671\n",
            "Epoch 135/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1253 - accuracy: 0.9672 - val_loss: 0.2552 - val_accuracy: 0.8951\n",
            "Epoch 136/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.0776 - accuracy: 0.9901 - val_loss: 0.2524 - val_accuracy: 0.9091\n",
            "Epoch 137/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0774 - accuracy: 0.9716 - val_loss: 0.2567 - val_accuracy: 0.9021\n",
            "Epoch 138/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0866 - accuracy: 0.9752 - val_loss: 0.2641 - val_accuracy: 0.9021\n",
            "Epoch 139/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1559 - accuracy: 0.9627 - val_loss: 0.2628 - val_accuracy: 0.9021\n",
            "Epoch 140/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0912 - accuracy: 0.9771 - val_loss: 0.2354 - val_accuracy: 0.9371\n",
            "Epoch 141/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.1026 - accuracy: 0.9658 - val_loss: 0.2628 - val_accuracy: 0.9021\n",
            "Epoch 142/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1047 - accuracy: 0.9749 - val_loss: 0.2554 - val_accuracy: 0.9161\n",
            "Epoch 143/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1225 - accuracy: 0.9675 - val_loss: 0.2452 - val_accuracy: 0.9231\n",
            "Epoch 144/500\n",
            "86/86 [==============================] - 27s 308ms/step - loss: 0.1371 - accuracy: 0.9494 - val_loss: 0.2957 - val_accuracy: 0.8881\n",
            "Epoch 145/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1189 - accuracy: 0.9714 - val_loss: 0.2541 - val_accuracy: 0.9021\n",
            "Epoch 146/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1046 - accuracy: 0.9585 - val_loss: 0.2446 - val_accuracy: 0.9091\n",
            "Epoch 147/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1170 - accuracy: 0.9720 - val_loss: 0.2792 - val_accuracy: 0.9021\n",
            "Epoch 148/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.0800 - accuracy: 0.9850 - val_loss: 0.3126 - val_accuracy: 0.8881\n",
            "Epoch 149/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.1569 - accuracy: 0.9494 - val_loss: 0.3047 - val_accuracy: 0.8881\n",
            "Epoch 150/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.1263 - accuracy: 0.9544 - val_loss: 0.2657 - val_accuracy: 0.9091\n",
            "Epoch 151/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0770 - accuracy: 0.9790 - val_loss: 0.2582 - val_accuracy: 0.9161\n",
            "Epoch 152/500\n",
            "86/86 [==============================] - 27s 319ms/step - loss: 0.1302 - accuracy: 0.9626 - val_loss: 0.2633 - val_accuracy: 0.9091\n",
            "Epoch 153/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0758 - accuracy: 0.9736 - val_loss: 0.2608 - val_accuracy: 0.9231\n",
            "Epoch 154/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.1019 - accuracy: 0.9722 - val_loss: 0.2545 - val_accuracy: 0.9161\n",
            "Epoch 155/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0925 - accuracy: 0.9688 - val_loss: 0.2686 - val_accuracy: 0.9021\n",
            "Epoch 156/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.1483 - accuracy: 0.9295 - val_loss: 0.2523 - val_accuracy: 0.9231\n",
            "Epoch 157/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.1087 - accuracy: 0.9719 - val_loss: 0.2552 - val_accuracy: 0.9091\n",
            "Epoch 158/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1279 - accuracy: 0.9693 - val_loss: 0.2687 - val_accuracy: 0.9021\n",
            "Epoch 159/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0497 - accuracy: 0.9924 - val_loss: 0.2502 - val_accuracy: 0.9231\n",
            "Epoch 160/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1212 - accuracy: 0.9525 - val_loss: 0.2318 - val_accuracy: 0.9301\n",
            "Epoch 161/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.1140 - accuracy: 0.9677 - val_loss: 0.2589 - val_accuracy: 0.9021\n",
            "Epoch 162/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0781 - accuracy: 0.9895 - val_loss: 0.2602 - val_accuracy: 0.9161\n",
            "Epoch 163/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.1140 - accuracy: 0.9704 - val_loss: 0.2446 - val_accuracy: 0.9161\n",
            "Epoch 164/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.1131 - accuracy: 0.9811 - val_loss: 0.2582 - val_accuracy: 0.9091\n",
            "Epoch 165/500\n",
            "86/86 [==============================] - 27s 308ms/step - loss: 0.0778 - accuracy: 0.9836 - val_loss: 0.2338 - val_accuracy: 0.9371\n",
            "Epoch 166/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0547 - accuracy: 0.9914 - val_loss: 0.2236 - val_accuracy: 0.9510\n",
            "Epoch 167/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0889 - accuracy: 0.9767 - val_loss: 0.2637 - val_accuracy: 0.8951\n",
            "Epoch 168/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1569 - accuracy: 0.9669 - val_loss: 0.2386 - val_accuracy: 0.9161\n",
            "Epoch 169/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1055 - accuracy: 0.9666 - val_loss: 0.2754 - val_accuracy: 0.9161\n",
            "Epoch 170/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0591 - accuracy: 0.9808 - val_loss: 0.2654 - val_accuracy: 0.9161\n",
            "Epoch 171/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0706 - accuracy: 0.9879 - val_loss: 0.2736 - val_accuracy: 0.9161\n",
            "Epoch 172/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0903 - accuracy: 0.9743 - val_loss: 0.2449 - val_accuracy: 0.9161\n",
            "Epoch 173/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0707 - accuracy: 0.9755 - val_loss: 0.2635 - val_accuracy: 0.9091\n",
            "Epoch 174/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0777 - accuracy: 0.9762 - val_loss: 0.2550 - val_accuracy: 0.9161\n",
            "Epoch 175/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.1346 - accuracy: 0.9692 - val_loss: 0.2539 - val_accuracy: 0.9161\n",
            "Epoch 176/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0961 - accuracy: 0.9800 - val_loss: 0.2607 - val_accuracy: 0.9091\n",
            "Epoch 177/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0781 - accuracy: 0.9665 - val_loss: 0.2742 - val_accuracy: 0.9021\n",
            "Epoch 178/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0937 - accuracy: 0.9741 - val_loss: 0.2696 - val_accuracy: 0.9091\n",
            "Epoch 179/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0947 - accuracy: 0.9678 - val_loss: 0.2556 - val_accuracy: 0.9231\n",
            "Epoch 180/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.1191 - accuracy: 0.9677 - val_loss: 0.2666 - val_accuracy: 0.9161\n",
            "Epoch 181/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0868 - accuracy: 0.9680 - val_loss: 0.2511 - val_accuracy: 0.9301\n",
            "Epoch 182/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0769 - accuracy: 0.9859 - val_loss: 0.2576 - val_accuracy: 0.9231\n",
            "Epoch 183/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.1202 - accuracy: 0.9507 - val_loss: 0.2658 - val_accuracy: 0.9231\n",
            "Epoch 184/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.1544 - accuracy: 0.9494 - val_loss: 0.2595 - val_accuracy: 0.9161\n",
            "Epoch 185/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0800 - accuracy: 0.9799 - val_loss: 0.2485 - val_accuracy: 0.9161\n",
            "Epoch 186/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0760 - accuracy: 0.9786 - val_loss: 0.2633 - val_accuracy: 0.9161\n",
            "Epoch 187/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0928 - accuracy: 0.9722 - val_loss: 0.2552 - val_accuracy: 0.9161\n",
            "Epoch 188/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0683 - accuracy: 0.9732 - val_loss: 0.2693 - val_accuracy: 0.9161\n",
            "Epoch 189/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0734 - accuracy: 0.9774 - val_loss: 0.2754 - val_accuracy: 0.9161\n",
            "Epoch 190/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0754 - accuracy: 0.9908 - val_loss: 0.2698 - val_accuracy: 0.9161\n",
            "Epoch 191/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0753 - accuracy: 0.9843 - val_loss: 0.2553 - val_accuracy: 0.9301\n",
            "Epoch 192/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0876 - accuracy: 0.9827 - val_loss: 0.2649 - val_accuracy: 0.9301\n",
            "Epoch 193/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0732 - accuracy: 0.9839 - val_loss: 0.2463 - val_accuracy: 0.9371\n",
            "Epoch 194/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0841 - accuracy: 0.9784 - val_loss: 0.2320 - val_accuracy: 0.9441\n",
            "Epoch 195/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0902 - accuracy: 0.9709 - val_loss: 0.2573 - val_accuracy: 0.9301\n",
            "Epoch 196/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.0702 - accuracy: 0.9779 - val_loss: 0.2473 - val_accuracy: 0.9301\n",
            "Epoch 197/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0440 - accuracy: 0.9980 - val_loss: 0.2592 - val_accuracy: 0.9301\n",
            "Epoch 198/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0828 - accuracy: 0.9713 - val_loss: 0.2943 - val_accuracy: 0.9161\n",
            "Epoch 199/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0816 - accuracy: 0.9715 - val_loss: 0.2916 - val_accuracy: 0.9091\n",
            "Epoch 200/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0921 - accuracy: 0.9612 - val_loss: 0.2554 - val_accuracy: 0.9231\n",
            "Epoch 201/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0624 - accuracy: 0.9918 - val_loss: 0.2344 - val_accuracy: 0.9301\n",
            "Epoch 202/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.1008 - accuracy: 0.9653 - val_loss: 0.2322 - val_accuracy: 0.9301\n",
            "Epoch 203/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0876 - accuracy: 0.9716 - val_loss: 0.2447 - val_accuracy: 0.9301\n",
            "Epoch 204/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0869 - accuracy: 0.9741 - val_loss: 0.2549 - val_accuracy: 0.9301\n",
            "Epoch 205/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0525 - accuracy: 0.9873 - val_loss: 0.2690 - val_accuracy: 0.9231\n",
            "Epoch 206/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0469 - accuracy: 0.9937 - val_loss: 0.2556 - val_accuracy: 0.9231\n",
            "Epoch 207/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0592 - accuracy: 0.9947 - val_loss: 0.2374 - val_accuracy: 0.9301\n",
            "Epoch 208/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0753 - accuracy: 0.9863 - val_loss: 0.2381 - val_accuracy: 0.9301\n",
            "Epoch 209/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.1332 - accuracy: 0.9598 - val_loss: 0.2580 - val_accuracy: 0.9301\n",
            "Epoch 210/500\n",
            "86/86 [==============================] - 26s 308ms/step - loss: 0.0850 - accuracy: 0.9699 - val_loss: 0.2545 - val_accuracy: 0.9301\n",
            "Epoch 211/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0861 - accuracy: 0.9729 - val_loss: 0.2446 - val_accuracy: 0.9231\n",
            "Epoch 212/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0867 - accuracy: 0.9702 - val_loss: 0.2498 - val_accuracy: 0.9301\n",
            "Epoch 213/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0701 - accuracy: 0.9805 - val_loss: 0.2559 - val_accuracy: 0.9231\n",
            "Epoch 214/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.0665 - accuracy: 0.9827 - val_loss: 0.2542 - val_accuracy: 0.9301\n",
            "Epoch 215/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0702 - accuracy: 0.9773 - val_loss: 0.2669 - val_accuracy: 0.9371\n",
            "Epoch 216/500\n",
            "86/86 [==============================] - 26s 307ms/step - loss: 0.0936 - accuracy: 0.9579 - val_loss: 0.2338 - val_accuracy: 0.9510\n",
            "Epoch 217/500\n",
            "86/86 [==============================] - 26s 306ms/step - loss: 0.0647 - accuracy: 0.9837 - val_loss: 0.2553 - val_accuracy: 0.9371\n",
            "Epoch 218/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0841 - accuracy: 0.9785 - val_loss: 0.2317 - val_accuracy: 0.9441\n",
            "Epoch 219/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0803 - accuracy: 0.9663 - val_loss: 0.2235 - val_accuracy: 0.9441\n",
            "Epoch 220/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0595 - accuracy: 0.9834 - val_loss: 0.2165 - val_accuracy: 0.9441\n",
            "Epoch 221/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0783 - accuracy: 0.9755 - val_loss: 0.2739 - val_accuracy: 0.9161\n",
            "Epoch 222/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0635 - accuracy: 0.9803 - val_loss: 0.2840 - val_accuracy: 0.9231\n",
            "Epoch 223/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0607 - accuracy: 0.9925 - val_loss: 0.2791 - val_accuracy: 0.9231\n",
            "Epoch 224/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0842 - accuracy: 0.9809 - val_loss: 0.2997 - val_accuracy: 0.9161\n",
            "Epoch 225/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0957 - accuracy: 0.9675 - val_loss: 0.2841 - val_accuracy: 0.9231\n",
            "Epoch 226/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0489 - accuracy: 0.9855 - val_loss: 0.2611 - val_accuracy: 0.9371\n",
            "Epoch 227/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0529 - accuracy: 0.9865 - val_loss: 0.2876 - val_accuracy: 0.9091\n",
            "Epoch 228/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0905 - accuracy: 0.9746 - val_loss: 0.2725 - val_accuracy: 0.9161\n",
            "Epoch 229/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0987 - accuracy: 0.9729 - val_loss: 0.2274 - val_accuracy: 0.9231\n",
            "Epoch 230/500\n",
            "86/86 [==============================] - 28s 320ms/step - loss: 0.0700 - accuracy: 0.9738 - val_loss: 0.2497 - val_accuracy: 0.9231\n",
            "Epoch 231/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0576 - accuracy: 0.9871 - val_loss: 0.2591 - val_accuracy: 0.9161\n",
            "Epoch 232/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0560 - accuracy: 0.9887 - val_loss: 0.2597 - val_accuracy: 0.9301\n",
            "Epoch 233/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0643 - accuracy: 0.9844 - val_loss: 0.2444 - val_accuracy: 0.9301\n",
            "Epoch 234/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0893 - accuracy: 0.9635 - val_loss: 0.2336 - val_accuracy: 0.9231\n",
            "Epoch 235/500\n",
            "86/86 [==============================] - 27s 319ms/step - loss: 0.0552 - accuracy: 0.9885 - val_loss: 0.2243 - val_accuracy: 0.9301\n",
            "Epoch 236/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0491 - accuracy: 0.9867 - val_loss: 0.2305 - val_accuracy: 0.9301\n",
            "Epoch 237/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0509 - accuracy: 0.9910 - val_loss: 0.2607 - val_accuracy: 0.9231\n",
            "Epoch 238/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0622 - accuracy: 0.9788 - val_loss: 0.2426 - val_accuracy: 0.9301\n",
            "Epoch 239/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0645 - accuracy: 0.9902 - val_loss: 0.2342 - val_accuracy: 0.9301\n",
            "Epoch 240/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0447 - accuracy: 0.9932 - val_loss: 0.2337 - val_accuracy: 0.9301\n",
            "Epoch 241/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0651 - accuracy: 0.9831 - val_loss: 0.2459 - val_accuracy: 0.9301\n",
            "Epoch 242/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0675 - accuracy: 0.9792 - val_loss: 0.2254 - val_accuracy: 0.9301\n",
            "Epoch 243/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0565 - accuracy: 0.9838 - val_loss: 0.2236 - val_accuracy: 0.9301\n",
            "Epoch 244/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0658 - accuracy: 0.9810 - val_loss: 0.2291 - val_accuracy: 0.9371\n",
            "Epoch 245/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0601 - accuracy: 0.9868 - val_loss: 0.2348 - val_accuracy: 0.9301\n",
            "Epoch 246/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0975 - accuracy: 0.9770 - val_loss: 0.2486 - val_accuracy: 0.9301\n",
            "Epoch 247/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0464 - accuracy: 0.9791 - val_loss: 0.2447 - val_accuracy: 0.9301\n",
            "Epoch 248/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0613 - accuracy: 0.9805 - val_loss: 0.2352 - val_accuracy: 0.9371\n",
            "Epoch 249/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0521 - accuracy: 0.9909 - val_loss: 0.2049 - val_accuracy: 0.9441\n",
            "Epoch 250/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.1096 - accuracy: 0.9640 - val_loss: 0.2320 - val_accuracy: 0.9371\n",
            "Epoch 251/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.2567 - val_accuracy: 0.9161\n",
            "Epoch 252/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0525 - accuracy: 0.9902 - val_loss: 0.2551 - val_accuracy: 0.9161\n",
            "Epoch 253/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0631 - accuracy: 0.9867 - val_loss: 0.2607 - val_accuracy: 0.9161\n",
            "Epoch 254/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0564 - accuracy: 0.9777 - val_loss: 0.2348 - val_accuracy: 0.9231\n",
            "Epoch 255/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0411 - accuracy: 0.9939 - val_loss: 0.2353 - val_accuracy: 0.9301\n",
            "Epoch 256/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0831 - accuracy: 0.9826 - val_loss: 0.2616 - val_accuracy: 0.9161\n",
            "Epoch 257/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0476 - accuracy: 0.9951 - val_loss: 0.2407 - val_accuracy: 0.9161\n",
            "Epoch 258/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0708 - accuracy: 0.9743 - val_loss: 0.2218 - val_accuracy: 0.9301\n",
            "Epoch 259/500\n",
            "86/86 [==============================] - 28s 323ms/step - loss: 0.0592 - accuracy: 0.9848 - val_loss: 0.2128 - val_accuracy: 0.9441\n",
            "Epoch 260/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0384 - accuracy: 0.9915 - val_loss: 0.2250 - val_accuracy: 0.9231\n",
            "Epoch 261/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0503 - accuracy: 0.9879 - val_loss: 0.2240 - val_accuracy: 0.9301\n",
            "Epoch 262/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0452 - accuracy: 0.9928 - val_loss: 0.2615 - val_accuracy: 0.9091\n",
            "Epoch 263/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0490 - accuracy: 0.9899 - val_loss: 0.2466 - val_accuracy: 0.9161\n",
            "Epoch 264/500\n",
            "86/86 [==============================] - 28s 321ms/step - loss: 0.0563 - accuracy: 0.9858 - val_loss: 0.2421 - val_accuracy: 0.9231\n",
            "Epoch 265/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0477 - accuracy: 0.9937 - val_loss: 0.2381 - val_accuracy: 0.9301\n",
            "Epoch 266/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0653 - accuracy: 0.9872 - val_loss: 0.2432 - val_accuracy: 0.9301\n",
            "Epoch 267/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0470 - accuracy: 0.9874 - val_loss: 0.2645 - val_accuracy: 0.9231\n",
            "Epoch 268/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0274 - accuracy: 0.9975 - val_loss: 0.2428 - val_accuracy: 0.9231\n",
            "Epoch 269/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0487 - accuracy: 0.9883 - val_loss: 0.2884 - val_accuracy: 0.9021\n",
            "Epoch 270/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0664 - accuracy: 0.9789 - val_loss: 0.2422 - val_accuracy: 0.9231\n",
            "Epoch 271/500\n",
            "86/86 [==============================] - 28s 325ms/step - loss: 0.0690 - accuracy: 0.9778 - val_loss: 0.2479 - val_accuracy: 0.9231\n",
            "Epoch 272/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0833 - accuracy: 0.9750 - val_loss: 0.2304 - val_accuracy: 0.9371\n",
            "Epoch 273/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0410 - accuracy: 0.9894 - val_loss: 0.2334 - val_accuracy: 0.9371\n",
            "Epoch 274/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0552 - accuracy: 0.9889 - val_loss: 0.2368 - val_accuracy: 0.9301\n",
            "Epoch 275/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0332 - accuracy: 0.9943 - val_loss: 0.2334 - val_accuracy: 0.9371\n",
            "Epoch 276/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0581 - accuracy: 0.9854 - val_loss: 0.2275 - val_accuracy: 0.9301\n",
            "Epoch 277/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0405 - accuracy: 0.9938 - val_loss: 0.2459 - val_accuracy: 0.9301\n",
            "Epoch 278/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0459 - accuracy: 0.9949 - val_loss: 0.2385 - val_accuracy: 0.9301\n",
            "Epoch 279/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0704 - accuracy: 0.9742 - val_loss: 0.2323 - val_accuracy: 0.9301\n",
            "Epoch 280/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0500 - accuracy: 0.9807 - val_loss: 0.2356 - val_accuracy: 0.9301\n",
            "Epoch 281/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0503 - accuracy: 0.9832 - val_loss: 0.2533 - val_accuracy: 0.9231\n",
            "Epoch 282/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 0.2632 - val_accuracy: 0.9091\n",
            "Epoch 283/500\n",
            "86/86 [==============================] - 28s 324ms/step - loss: 0.0410 - accuracy: 0.9876 - val_loss: 0.2302 - val_accuracy: 0.9371\n",
            "Epoch 284/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0631 - accuracy: 0.9814 - val_loss: 0.2262 - val_accuracy: 0.9371\n",
            "Epoch 285/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0695 - accuracy: 0.9787 - val_loss: 0.2321 - val_accuracy: 0.9371\n",
            "Epoch 286/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0606 - accuracy: 0.9810 - val_loss: 0.2073 - val_accuracy: 0.9371\n",
            "Epoch 287/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0405 - accuracy: 0.9868 - val_loss: 0.2391 - val_accuracy: 0.9301\n",
            "Epoch 288/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0322 - accuracy: 0.9972 - val_loss: 0.2167 - val_accuracy: 0.9301\n",
            "Epoch 289/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0426 - accuracy: 0.9832 - val_loss: 0.2425 - val_accuracy: 0.9301\n",
            "Epoch 290/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0761 - accuracy: 0.9699 - val_loss: 0.2497 - val_accuracy: 0.9161\n",
            "Epoch 291/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0482 - accuracy: 0.9868 - val_loss: 0.2465 - val_accuracy: 0.9231\n",
            "Epoch 292/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0422 - accuracy: 0.9920 - val_loss: 0.2335 - val_accuracy: 0.9301\n",
            "Epoch 293/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0621 - accuracy: 0.9815 - val_loss: 0.2304 - val_accuracy: 0.9301\n",
            "Epoch 294/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0528 - accuracy: 0.9775 - val_loss: 0.2409 - val_accuracy: 0.9231\n",
            "Epoch 295/500\n",
            "86/86 [==============================] - 27s 319ms/step - loss: 0.0559 - accuracy: 0.9843 - val_loss: 0.2436 - val_accuracy: 0.9301\n",
            "Epoch 296/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0857 - accuracy: 0.9706 - val_loss: 0.2453 - val_accuracy: 0.9161\n",
            "Epoch 297/500\n",
            "86/86 [==============================] - 27s 320ms/step - loss: 0.0523 - accuracy: 0.9857 - val_loss: 0.2419 - val_accuracy: 0.9301\n",
            "Epoch 298/500\n",
            "86/86 [==============================] - 27s 320ms/step - loss: 0.0357 - accuracy: 0.9937 - val_loss: 0.2508 - val_accuracy: 0.9301\n",
            "Epoch 299/500\n",
            "86/86 [==============================] - 27s 319ms/step - loss: 0.0684 - accuracy: 0.9810 - val_loss: 0.2104 - val_accuracy: 0.9301\n",
            "Epoch 300/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0557 - accuracy: 0.9797 - val_loss: 0.1991 - val_accuracy: 0.9441\n",
            "Epoch 301/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0370 - accuracy: 0.9955 - val_loss: 0.2146 - val_accuracy: 0.9371\n",
            "Epoch 302/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0400 - accuracy: 0.9968 - val_loss: 0.1969 - val_accuracy: 0.9510\n",
            "Epoch 303/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0519 - accuracy: 0.9820 - val_loss: 0.2107 - val_accuracy: 0.9371\n",
            "Epoch 304/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0279 - accuracy: 0.9951 - val_loss: 0.2237 - val_accuracy: 0.9371\n",
            "Epoch 305/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0433 - accuracy: 0.9862 - val_loss: 0.2039 - val_accuracy: 0.9510\n",
            "Epoch 306/500\n",
            "86/86 [==============================] - 28s 321ms/step - loss: 0.0583 - accuracy: 0.9821 - val_loss: 0.2221 - val_accuracy: 0.9371\n",
            "Epoch 307/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0418 - accuracy: 0.9871 - val_loss: 0.2197 - val_accuracy: 0.9301\n",
            "Epoch 308/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0453 - accuracy: 0.9891 - val_loss: 0.2328 - val_accuracy: 0.9301\n",
            "Epoch 309/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0466 - accuracy: 0.9920 - val_loss: 0.2224 - val_accuracy: 0.9301\n",
            "Epoch 310/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.2107 - val_accuracy: 0.9301\n",
            "Epoch 311/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0337 - accuracy: 0.9862 - val_loss: 0.2377 - val_accuracy: 0.9301\n",
            "Epoch 312/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0649 - accuracy: 0.9787 - val_loss: 0.2592 - val_accuracy: 0.9231\n",
            "Epoch 313/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0629 - accuracy: 0.9850 - val_loss: 0.2300 - val_accuracy: 0.9301\n",
            "Epoch 314/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0293 - accuracy: 0.9945 - val_loss: 0.2315 - val_accuracy: 0.9301\n",
            "Epoch 315/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0578 - accuracy: 0.9814 - val_loss: 0.2146 - val_accuracy: 0.9371\n",
            "Epoch 316/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9371\n",
            "Epoch 317/500\n",
            "86/86 [==============================] - 27s 319ms/step - loss: 0.0423 - accuracy: 0.9934 - val_loss: 0.2042 - val_accuracy: 0.9371\n",
            "Epoch 318/500\n",
            "86/86 [==============================] - 28s 323ms/step - loss: 0.0519 - accuracy: 0.9849 - val_loss: 0.2127 - val_accuracy: 0.9441\n",
            "Epoch 319/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.2201 - val_accuracy: 0.9441\n",
            "Epoch 320/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0490 - accuracy: 0.9831 - val_loss: 0.2050 - val_accuracy: 0.9441\n",
            "Epoch 321/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0474 - accuracy: 0.9858 - val_loss: 0.2246 - val_accuracy: 0.9441\n",
            "Epoch 322/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0412 - accuracy: 0.9924 - val_loss: 0.2087 - val_accuracy: 0.9441\n",
            "Epoch 323/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0282 - accuracy: 0.9962 - val_loss: 0.2254 - val_accuracy: 0.9371\n",
            "Epoch 324/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0371 - accuracy: 0.9888 - val_loss: 0.2140 - val_accuracy: 0.9441\n",
            "Epoch 325/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0301 - accuracy: 0.9936 - val_loss: 0.2458 - val_accuracy: 0.9301\n",
            "Epoch 326/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0212 - accuracy: 0.9997 - val_loss: 0.2226 - val_accuracy: 0.9441\n",
            "Epoch 327/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.2469 - val_accuracy: 0.9231\n",
            "Epoch 328/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0505 - accuracy: 0.9822 - val_loss: 0.2716 - val_accuracy: 0.9161\n",
            "Epoch 329/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0393 - accuracy: 0.9952 - val_loss: 0.2495 - val_accuracy: 0.9301\n",
            "Epoch 330/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0466 - accuracy: 0.9845 - val_loss: 0.2402 - val_accuracy: 0.9231\n",
            "Epoch 331/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0617 - accuracy: 0.9802 - val_loss: 0.2204 - val_accuracy: 0.9441\n",
            "Epoch 332/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0369 - accuracy: 0.9898 - val_loss: 0.2160 - val_accuracy: 0.9441\n",
            "Epoch 333/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0457 - accuracy: 0.9876 - val_loss: 0.2331 - val_accuracy: 0.9301\n",
            "Epoch 334/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0412 - accuracy: 0.9885 - val_loss: 0.2353 - val_accuracy: 0.9441\n",
            "Epoch 335/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0623 - accuracy: 0.9893 - val_loss: 0.2453 - val_accuracy: 0.9371\n",
            "Epoch 336/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.2862 - val_accuracy: 0.9161\n",
            "Epoch 337/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0278 - accuracy: 0.9945 - val_loss: 0.2480 - val_accuracy: 0.9371\n",
            "Epoch 338/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0391 - accuracy: 0.9830 - val_loss: 0.2091 - val_accuracy: 0.9441\n",
            "Epoch 339/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0729 - accuracy: 0.9673 - val_loss: 0.2266 - val_accuracy: 0.9371\n",
            "Epoch 340/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0279 - accuracy: 0.9955 - val_loss: 0.2189 - val_accuracy: 0.9441\n",
            "Epoch 341/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0452 - accuracy: 0.9802 - val_loss: 0.2262 - val_accuracy: 0.9441\n",
            "Epoch 342/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0538 - accuracy: 0.9803 - val_loss: 0.2083 - val_accuracy: 0.9441\n",
            "Epoch 343/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0267 - accuracy: 0.9968 - val_loss: 0.2287 - val_accuracy: 0.9301\n",
            "Epoch 344/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0350 - accuracy: 0.9957 - val_loss: 0.2300 - val_accuracy: 0.9441\n",
            "Epoch 345/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0254 - accuracy: 0.9943 - val_loss: 0.2038 - val_accuracy: 0.9441\n",
            "Epoch 346/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0332 - accuracy: 0.9940 - val_loss: 0.2095 - val_accuracy: 0.9441\n",
            "Epoch 347/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0429 - accuracy: 0.9840 - val_loss: 0.1941 - val_accuracy: 0.9441\n",
            "Epoch 348/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0188 - accuracy: 0.9974 - val_loss: 0.2106 - val_accuracy: 0.9371\n",
            "Epoch 349/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0254 - accuracy: 0.9904 - val_loss: 0.1836 - val_accuracy: 0.9441\n",
            "Epoch 350/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0299 - accuracy: 0.9940 - val_loss: 0.1978 - val_accuracy: 0.9441\n",
            "Epoch 351/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0429 - accuracy: 0.9917 - val_loss: 0.2051 - val_accuracy: 0.9441\n",
            "Epoch 352/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0487 - accuracy: 0.9935 - val_loss: 0.1989 - val_accuracy: 0.9441\n",
            "Epoch 353/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0521 - accuracy: 0.9898 - val_loss: 0.2056 - val_accuracy: 0.9441\n",
            "Epoch 354/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0509 - accuracy: 0.9750 - val_loss: 0.2007 - val_accuracy: 0.9441\n",
            "Epoch 355/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0179 - accuracy: 0.9980 - val_loss: 0.2258 - val_accuracy: 0.9371\n",
            "Epoch 356/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0458 - accuracy: 0.9907 - val_loss: 0.2080 - val_accuracy: 0.9441\n",
            "Epoch 357/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.1981 - val_accuracy: 0.9441\n",
            "Epoch 358/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0409 - accuracy: 0.9911 - val_loss: 0.2090 - val_accuracy: 0.9441\n",
            "Epoch 359/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9441\n",
            "Epoch 360/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0208 - accuracy: 0.9956 - val_loss: 0.2075 - val_accuracy: 0.9441\n",
            "Epoch 361/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0503 - accuracy: 0.9813 - val_loss: 0.2049 - val_accuracy: 0.9441\n",
            "Epoch 362/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9441\n",
            "Epoch 363/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0260 - accuracy: 0.9960 - val_loss: 0.2177 - val_accuracy: 0.9441\n",
            "Epoch 364/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0372 - accuracy: 0.9916 - val_loss: 0.2121 - val_accuracy: 0.9441\n",
            "Epoch 365/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0443 - accuracy: 0.9904 - val_loss: 0.2119 - val_accuracy: 0.9441\n",
            "Epoch 366/500\n",
            "86/86 [==============================] - 28s 326ms/step - loss: 0.0272 - accuracy: 0.9974 - val_loss: 0.2094 - val_accuracy: 0.9441\n",
            "Epoch 367/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0369 - accuracy: 0.9893 - val_loss: 0.2464 - val_accuracy: 0.9371\n",
            "Epoch 368/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0274 - accuracy: 0.9952 - val_loss: 0.2340 - val_accuracy: 0.9441\n",
            "Epoch 369/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0243 - accuracy: 0.9985 - val_loss: 0.2401 - val_accuracy: 0.9371\n",
            "Epoch 370/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0352 - accuracy: 0.9828 - val_loss: 0.2485 - val_accuracy: 0.9371\n",
            "Epoch 371/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0232 - accuracy: 0.9988 - val_loss: 0.2566 - val_accuracy: 0.9371\n",
            "Epoch 372/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0291 - accuracy: 0.9963 - val_loss: 0.2070 - val_accuracy: 0.9441\n",
            "Epoch 373/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0309 - accuracy: 0.9856 - val_loss: 0.1816 - val_accuracy: 0.9510\n",
            "Epoch 374/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.2155 - val_accuracy: 0.9371\n",
            "Epoch 375/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0206 - accuracy: 0.9961 - val_loss: 0.2355 - val_accuracy: 0.9301\n",
            "Epoch 376/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0289 - accuracy: 0.9960 - val_loss: 0.2477 - val_accuracy: 0.9301\n",
            "Epoch 377/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0478 - accuracy: 0.9865 - val_loss: 0.1872 - val_accuracy: 0.9510\n",
            "Epoch 378/500\n",
            "86/86 [==============================] - 28s 321ms/step - loss: 0.0416 - accuracy: 0.9930 - val_loss: 0.2181 - val_accuracy: 0.9371\n",
            "Epoch 379/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0438 - accuracy: 0.9851 - val_loss: 0.2103 - val_accuracy: 0.9371\n",
            "Epoch 380/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0432 - accuracy: 0.9914 - val_loss: 0.2321 - val_accuracy: 0.9371\n",
            "Epoch 381/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.2683 - val_accuracy: 0.9161\n",
            "Epoch 382/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0396 - accuracy: 0.9909 - val_loss: 0.2239 - val_accuracy: 0.9301\n",
            "Epoch 383/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.2381 - val_accuracy: 0.9231\n",
            "Epoch 384/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0389 - accuracy: 0.9848 - val_loss: 0.2327 - val_accuracy: 0.9301\n",
            "Epoch 385/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0274 - accuracy: 0.9949 - val_loss: 0.2474 - val_accuracy: 0.9231\n",
            "Epoch 386/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0392 - accuracy: 0.9878 - val_loss: 0.2195 - val_accuracy: 0.9301\n",
            "Epoch 387/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0227 - accuracy: 0.9993 - val_loss: 0.2086 - val_accuracy: 0.9510\n",
            "Epoch 388/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0254 - accuracy: 0.9957 - val_loss: 0.2238 - val_accuracy: 0.9441\n",
            "Epoch 389/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0235 - accuracy: 0.9950 - val_loss: 0.2109 - val_accuracy: 0.9371\n",
            "Epoch 390/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0357 - accuracy: 0.9871 - val_loss: 0.2123 - val_accuracy: 0.9301\n",
            "Epoch 391/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0326 - accuracy: 0.9931 - val_loss: 0.2215 - val_accuracy: 0.9371\n",
            "Epoch 392/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0358 - accuracy: 0.9833 - val_loss: 0.2518 - val_accuracy: 0.9371\n",
            "Epoch 393/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0239 - accuracy: 0.9983 - val_loss: 0.2173 - val_accuracy: 0.9371\n",
            "Epoch 394/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0324 - accuracy: 0.9864 - val_loss: 0.2296 - val_accuracy: 0.9371\n",
            "Epoch 395/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0191 - accuracy: 0.9995 - val_loss: 0.2135 - val_accuracy: 0.9371\n",
            "Epoch 396/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 0.2269 - val_accuracy: 0.9441\n",
            "Epoch 397/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0399 - accuracy: 0.9924 - val_loss: 0.2083 - val_accuracy: 0.9441\n",
            "Epoch 398/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0205 - accuracy: 0.9923 - val_loss: 0.2288 - val_accuracy: 0.9371\n",
            "Epoch 399/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0258 - accuracy: 0.9904 - val_loss: 0.2202 - val_accuracy: 0.9441\n",
            "Epoch 400/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0247 - accuracy: 0.9940 - val_loss: 0.2490 - val_accuracy: 0.9301\n",
            "Epoch 401/500\n",
            "86/86 [==============================] - 28s 322ms/step - loss: 0.0403 - accuracy: 0.9851 - val_loss: 0.2409 - val_accuracy: 0.9371\n",
            "Epoch 402/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0234 - accuracy: 0.9973 - val_loss: 0.2114 - val_accuracy: 0.9441\n",
            "Epoch 403/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.2371 - val_accuracy: 0.9371\n",
            "Epoch 404/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0180 - accuracy: 0.9984 - val_loss: 0.2253 - val_accuracy: 0.9441\n",
            "Epoch 405/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0192 - accuracy: 0.9960 - val_loss: 0.2509 - val_accuracy: 0.9301\n",
            "Epoch 406/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0374 - accuracy: 0.9833 - val_loss: 0.2686 - val_accuracy: 0.9161\n",
            "Epoch 407/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0235 - accuracy: 0.9965 - val_loss: 0.2371 - val_accuracy: 0.9371\n",
            "Epoch 408/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0462 - accuracy: 0.9911 - val_loss: 0.2436 - val_accuracy: 0.9301\n",
            "Epoch 409/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0325 - accuracy: 0.9909 - val_loss: 0.2193 - val_accuracy: 0.9510\n",
            "Epoch 410/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.2397 - val_accuracy: 0.9301\n",
            "Epoch 411/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0286 - accuracy: 0.9981 - val_loss: 0.2335 - val_accuracy: 0.9301\n",
            "Epoch 412/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0374 - accuracy: 0.9912 - val_loss: 0.2371 - val_accuracy: 0.9301\n",
            "Epoch 413/500\n",
            "86/86 [==============================] - 28s 321ms/step - loss: 0.0235 - accuracy: 0.9962 - val_loss: 0.2074 - val_accuracy: 0.9441\n",
            "Epoch 414/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0334 - accuracy: 0.9798 - val_loss: 0.2325 - val_accuracy: 0.9301\n",
            "Epoch 415/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0152 - accuracy: 0.9997 - val_loss: 0.2140 - val_accuracy: 0.9441\n",
            "Epoch 416/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0285 - accuracy: 0.9943 - val_loss: 0.2073 - val_accuracy: 0.9510\n",
            "Epoch 417/500\n",
            "86/86 [==============================] - 27s 310ms/step - loss: 0.0297 - accuracy: 0.9972 - val_loss: 0.2060 - val_accuracy: 0.9510\n",
            "Epoch 418/500\n",
            "86/86 [==============================] - 27s 309ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.2186 - val_accuracy: 0.9441\n",
            "Epoch 419/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0214 - accuracy: 0.9984 - val_loss: 0.2012 - val_accuracy: 0.9510\n",
            "Epoch 420/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0416 - accuracy: 0.9923 - val_loss: 0.2061 - val_accuracy: 0.9510\n",
            "Epoch 421/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.1929 - val_accuracy: 0.9510\n",
            "Epoch 422/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.1978 - val_accuracy: 0.9510\n",
            "Epoch 423/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0226 - accuracy: 0.9979 - val_loss: 0.2089 - val_accuracy: 0.9371\n",
            "Epoch 424/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0262 - accuracy: 0.9960 - val_loss: 0.2387 - val_accuracy: 0.9301\n",
            "Epoch 425/500\n",
            "86/86 [==============================] - 28s 322ms/step - loss: 0.0190 - accuracy: 0.9973 - val_loss: 0.2323 - val_accuracy: 0.9371\n",
            "Epoch 426/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.2357 - val_accuracy: 0.9371\n",
            "Epoch 427/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0190 - accuracy: 0.9979 - val_loss: 0.2010 - val_accuracy: 0.9371\n",
            "Epoch 428/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.2341 - val_accuracy: 0.9371\n",
            "Epoch 429/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0266 - accuracy: 0.9936 - val_loss: 0.2302 - val_accuracy: 0.9371\n",
            "Epoch 430/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0334 - accuracy: 0.9937 - val_loss: 0.2204 - val_accuracy: 0.9441\n",
            "Epoch 431/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0224 - accuracy: 0.9966 - val_loss: 0.1956 - val_accuracy: 0.9510\n",
            "Epoch 432/500\n",
            "86/86 [==============================] - 27s 319ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9441\n",
            "Epoch 433/500\n",
            "86/86 [==============================] - 28s 323ms/step - loss: 0.0129 - accuracy: 0.9994 - val_loss: 0.2238 - val_accuracy: 0.9371\n",
            "Epoch 434/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0337 - accuracy: 0.9939 - val_loss: 0.1931 - val_accuracy: 0.9441\n",
            "Epoch 435/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0163 - accuracy: 0.9994 - val_loss: 0.2212 - val_accuracy: 0.9371\n",
            "Epoch 436/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.2027 - val_accuracy: 0.9441\n",
            "Epoch 437/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0268 - accuracy: 0.9924 - val_loss: 0.2539 - val_accuracy: 0.9231\n",
            "Epoch 438/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0347 - accuracy: 0.9807 - val_loss: 0.2590 - val_accuracy: 0.9161\n",
            "Epoch 439/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0359 - accuracy: 0.9860 - val_loss: 0.2889 - val_accuracy: 0.9161\n",
            "Epoch 440/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0253 - accuracy: 0.9956 - val_loss: 0.2617 - val_accuracy: 0.9231\n",
            "Epoch 441/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0154 - accuracy: 0.9981 - val_loss: 0.2593 - val_accuracy: 0.9231\n",
            "Epoch 442/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0302 - accuracy: 0.9842 - val_loss: 0.2623 - val_accuracy: 0.9231\n",
            "Epoch 443/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0121 - accuracy: 0.9995 - val_loss: 0.2645 - val_accuracy: 0.9231\n",
            "Epoch 444/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9161\n",
            "Epoch 445/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9301\n",
            "Epoch 446/500\n",
            "86/86 [==============================] - 27s 319ms/step - loss: 0.0141 - accuracy: 0.9980 - val_loss: 0.2650 - val_accuracy: 0.9231\n",
            "Epoch 447/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0249 - accuracy: 0.9977 - val_loss: 0.2277 - val_accuracy: 0.9371\n",
            "Epoch 448/500\n",
            "86/86 [==============================] - 28s 320ms/step - loss: 0.0209 - accuracy: 0.9975 - val_loss: 0.2058 - val_accuracy: 0.9371\n",
            "Epoch 449/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0392 - accuracy: 0.9921 - val_loss: 0.2256 - val_accuracy: 0.9371\n",
            "Epoch 450/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0140 - accuracy: 0.9943 - val_loss: 0.2403 - val_accuracy: 0.9371\n",
            "Epoch 451/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0395 - accuracy: 0.9873 - val_loss: 0.2062 - val_accuracy: 0.9371\n",
            "Epoch 452/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9371\n",
            "Epoch 453/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0176 - accuracy: 0.9986 - val_loss: 0.2474 - val_accuracy: 0.9231\n",
            "Epoch 454/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.2256 - val_accuracy: 0.9371\n",
            "Epoch 455/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0431 - accuracy: 0.9868 - val_loss: 0.2398 - val_accuracy: 0.9371\n",
            "Epoch 456/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0146 - accuracy: 0.9993 - val_loss: 0.2450 - val_accuracy: 0.9301\n",
            "Epoch 457/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0266 - accuracy: 0.9945 - val_loss: 0.2311 - val_accuracy: 0.9301\n",
            "Epoch 458/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0153 - accuracy: 0.9997 - val_loss: 0.2481 - val_accuracy: 0.9301\n",
            "Epoch 459/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0235 - accuracy: 0.9882 - val_loss: 0.2647 - val_accuracy: 0.9301\n",
            "Epoch 460/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0216 - accuracy: 0.9998 - val_loss: 0.2283 - val_accuracy: 0.9371\n",
            "Epoch 461/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0218 - accuracy: 0.9962 - val_loss: 0.2499 - val_accuracy: 0.9371\n",
            "Epoch 462/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.2345 - val_accuracy: 0.9301\n",
            "Epoch 463/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.2432 - val_accuracy: 0.9301\n",
            "Epoch 464/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0301 - accuracy: 0.9933 - val_loss: 0.2551 - val_accuracy: 0.9231\n",
            "Epoch 465/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0246 - accuracy: 0.9896 - val_loss: 0.2255 - val_accuracy: 0.9371\n",
            "Epoch 466/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0300 - accuracy: 0.9835 - val_loss: 0.2606 - val_accuracy: 0.9371\n",
            "Epoch 467/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9441\n",
            "Epoch 468/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0164 - accuracy: 0.9982 - val_loss: 0.2249 - val_accuracy: 0.9371\n",
            "Epoch 469/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9371\n",
            "Epoch 470/500\n",
            "86/86 [==============================] - 27s 311ms/step - loss: 0.0121 - accuracy: 0.9991 - val_loss: 0.1840 - val_accuracy: 0.9510\n",
            "Epoch 471/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0305 - accuracy: 0.9949 - val_loss: 0.2031 - val_accuracy: 0.9441\n",
            "Epoch 472/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0291 - accuracy: 0.9995 - val_loss: 0.2238 - val_accuracy: 0.9301\n",
            "Epoch 473/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0195 - accuracy: 0.9959 - val_loss: 0.2275 - val_accuracy: 0.9301\n",
            "Epoch 474/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0411 - accuracy: 0.9951 - val_loss: 0.2456 - val_accuracy: 0.9301\n",
            "Epoch 475/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0245 - accuracy: 0.9973 - val_loss: 0.2980 - val_accuracy: 0.9161\n",
            "Epoch 476/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0410 - accuracy: 0.9897 - val_loss: 0.2223 - val_accuracy: 0.9441\n",
            "Epoch 477/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.1990 - val_accuracy: 0.9441\n",
            "Epoch 478/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0283 - accuracy: 0.9970 - val_loss: 0.2296 - val_accuracy: 0.9371\n",
            "Epoch 479/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0265 - accuracy: 0.9997 - val_loss: 0.2145 - val_accuracy: 0.9441\n",
            "Epoch 480/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.2353 - val_accuracy: 0.9301\n",
            "Epoch 481/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.2324 - val_accuracy: 0.9301\n",
            "Epoch 482/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0166 - accuracy: 0.9901 - val_loss: 0.2408 - val_accuracy: 0.9301\n",
            "Epoch 483/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9301\n",
            "Epoch 484/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0172 - accuracy: 0.9985 - val_loss: 0.2427 - val_accuracy: 0.9301\n",
            "Epoch 485/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.2425 - val_accuracy: 0.9371\n",
            "Epoch 486/500\n",
            "86/86 [==============================] - 27s 317ms/step - loss: 0.0196 - accuracy: 0.9912 - val_loss: 0.2079 - val_accuracy: 0.9441\n",
            "Epoch 487/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0210 - accuracy: 0.9869 - val_loss: 0.2085 - val_accuracy: 0.9371\n",
            "Epoch 488/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9371\n",
            "Epoch 489/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 0.2152 - val_accuracy: 0.9371\n",
            "Epoch 490/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0124 - accuracy: 0.9988 - val_loss: 0.2110 - val_accuracy: 0.9301\n",
            "Epoch 491/500\n",
            "86/86 [==============================] - 27s 318ms/step - loss: 0.0279 - accuracy: 0.9824 - val_loss: 0.2387 - val_accuracy: 0.9301\n",
            "Epoch 492/500\n",
            "86/86 [==============================] - 27s 316ms/step - loss: 0.0376 - accuracy: 0.9914 - val_loss: 0.2198 - val_accuracy: 0.9301\n",
            "Epoch 493/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0256 - accuracy: 0.9994 - val_loss: 0.2364 - val_accuracy: 0.9231\n",
            "Epoch 494/500\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.2235 - val_accuracy: 0.9371\n",
            "Epoch 495/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0278 - accuracy: 0.9884 - val_loss: 0.2109 - val_accuracy: 0.9371\n",
            "Epoch 496/500\n",
            "86/86 [==============================] - 28s 321ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.2169 - val_accuracy: 0.9441\n",
            "Epoch 497/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.1763 - val_accuracy: 0.9441\n",
            "Epoch 498/500\n",
            "86/86 [==============================] - 27s 312ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.2187 - val_accuracy: 0.9371\n",
            "Epoch 499/500\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.0214 - accuracy: 0.9907 - val_loss: 0.2161 - val_accuracy: 0.9371\n",
            "Epoch 500/500\n",
            "86/86 [==============================] - 27s 313ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd0ysq0_q4Sq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468614bf-f11c-4f6a-e0b7-a20bd7ae54d8"
      },
      "source": [
        "print(\"Accuracy of the model : \", model.evaluate(x_validate, y_validate)[1] * 100, \"%\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 301ms/step - loss: 0.2304 - accuracy: 0.9371\n",
            "Accuracy of the model :  93.7062919139862 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdzu1Jqqq_eQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "796da942-263c-45ff-9e8e-b200eb006602"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\r\n",
        "axs[0].plot(range(1, len(history.history[\"accuracy\"]) + 1), history.history[\"accuracy\"])\r\n",
        "axs[0].plot(range(1, len(history.history[\"val_accuracy\"]) + 1), history.history[\"val_accuracy\"])\r\n",
        "axs[0].set_title(\"Model Accuracy\")\r\n",
        "axs[0].set_ylabel(\"Accuracy\")\r\n",
        "axs[0].set_xlabel(\"Epoch\")\r\n",
        "axs[0].set_xticks(np.arange(1, len(history.history[\"accuracy\"]) + 1), len(history.history[\"accuracy\"]) / 10)\r\n",
        "axs[0].legend([\"train\", \"val\"], loc=\"best\")\r\n",
        "axs[1].plot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"loss\"])\r\n",
        "axs[1].plot(range(1, len(history.history[\"val_loss\"]) + 1), history.history[\"val_loss\"])\r\n",
        "axs[1].set_title(\"Model Loss\")\r\n",
        "axs[1].set_ylabel(\"Loss\")\r\n",
        "axs[1].set_xlabel(\"Epoch\")\r\n",
        "axs[1].set_xticks(np.arange(1, len(history.history[\"loss\"]) + 1), len(history.history[\"loss\"]) / 10)\r\n",
        "axs[1].legend([\"train\", \"val\"], loc=\"best\")\r\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: MatplotlibDeprecationWarning: Passing the minor parameter of set_xticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Passing the minor parameter of set_xticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi8HoCVGra-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234a3f9d-d474-42e8-a2ec-aeead11aa1c5"
      },
      "source": [
        "predictions = model.predict_classes(x_test)\r\n",
        "print(predictions)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 128, 96, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 96, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 96, 128, 1).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[6 4 2 3 2 0 2 2 2 4 1 3 5 5 4 4 6 2 0 0 3 0 1 6 0 1 6 0 4 5 6 6 3 3 3 2 6\n",
            " 4 4 2 4 3 6 1 2 5 4 5 3 3 0 4 6 3 2 1 6 0 1 1 0 0 5 3 3 1 3 3 5 1 3 4 2 0\n",
            " 0 2 3 1 0 0 4 4 6 2 1 3 6 3 3 5 3 3 1 1 5 2 3 1 2 0 1 3 5 3 1 3 1 4 6 0 4\n",
            " 1 6 2 0 4 1 2 6 2 0 2 2 5 4 5 0 2 3 0 3 3 0 5 3 2 0 2 6 4 5 3 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riTDFMk5rfLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b28382-4c96-4d11-e1b4-e7cf646b4b39"
      },
      "source": [
        "classes = [\"Class \" + str(i) for i in range(8) if i != 0]\r\n",
        "print(classification_report(y, predictions, target_names=classes))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 1       1.00      0.85      0.92        27\n",
            "     Class 2       0.95      1.00      0.97        18\n",
            "     Class 3       0.83      1.00      0.90        19\n",
            "     Class 4       1.00      1.00      1.00        30\n",
            "     Class 5       1.00      1.00      1.00        18\n",
            "     Class 6       1.00      0.93      0.97        15\n",
            "     Class 7       1.00      1.00      1.00        16\n",
            "\n",
            "    accuracy                           0.97       143\n",
            "   macro avg       0.97      0.97      0.97       143\n",
            "weighted avg       0.97      0.97      0.97       143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQBG9JD3sYhi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "67ef65d6-f208-426a-9d61-e833c5b3376a"
      },
      "source": [
        "cm = confusion_matrix(y, predictions)\r\n",
        "cm = pd.DataFrame(cm, index=[i for i in range(8) if i != 0], columns=[i for i in range(8) if i != 0])\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "sns.heatmap(cm, cmap=\"Blues\", linecolor='black', linewidth=1, annot=True, fmt='')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ebf554f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_WFWeoqsinY"
      },
      "source": [
        "correct = (predictions == y).to_numpy().nonzero()[0]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOhS2JEjsk8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "1bd5326d-5211-4533-a104-ee8554fa906c"
      },
      "source": [
        "i = 0\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "for c in correct[:9]:\r\n",
        "    plt.subplot(3, 3, i + 1)\r\n",
        "    plt.imshow(x_test[c].reshape(image_height, image_width), cmap=\"gray\", interpolation='none')\r\n",
        "    plt.title(\"Predicted Class {}\\n Actual Class {}\".format(flavors[predictions[c]], flavors[y[c]]))\r\n",
        "    i += 1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-769f0aaf558d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ]
}